{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595f3d60-d7c6-43d9-be03-2cf644b05400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†æ–‡ä»¶: global_jobs_salaries_2024.csv\n",
      "ğŸ“Œ æ£€æµ‹åˆ°ç¼–ç : ascii\n",
      "âŒ è¯»å– global_jobs_salaries_2024.csv å¤±è´¥ï¼Œä½¿ç”¨ asciiï¼Œå°è¯•å…¶ä»–ç¼–ç ...\n",
      "âœ… æˆåŠŸä½¿ç”¨ utf-8 è¯»å– global_jobs_salaries_2024.csv\n",
      "ğŸ“Œ å‘ç°è–ªèµ„åˆ—: Salary\n",
      "âœ… æ¸…ç†å®Œæˆï¼Œå·²ä¿å­˜è‡³: G:\\Nextcloud\\FSU_Cloud\\Big Data\\Projekt\\cleaned_data\\cleaned_global_jobs_salaries_2024.csv\n",
      "\n",
      "ğŸ‰ æ‰€æœ‰ CSV æ–‡ä»¶å·²å¤„ç†å®Œæ¯•ï¼Œæ¸…ç†åçš„æ–‡ä»¶å­˜æ”¾åœ¨ `G:\\Nextcloud\\FSU_Cloud\\Big Data\\Projekt\\cleaned_data` æ–‡ä»¶å¤¹ä¸­ï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# 1ï¸âƒ£ è·å–å½“å‰ Notebook æ‰€åœ¨ç›®å½•\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 2ï¸âƒ£ è·å– `Projekt` æ ¹ç›®å½•ï¼ˆå³ `raw_data` çš„ä¸Šä¸€çº§ç›®å½•ï¼‰\n",
    "projekt_root = os.path.abspath(os.path.join(current_dir, \"..\", \"..\"))\n",
    "\n",
    "# 3ï¸âƒ£ å®šä¹‰ `cleaned_data` ç›®å½•çš„æ­£ç¡®è·¯å¾„\n",
    "cleaned_data_dir = os.path.join(projekt_root, \"cleaned_data\")\n",
    "\n",
    "# 4ï¸âƒ£ ç¡®ä¿ `cleaned_data` ç›®å½•å­˜åœ¨\n",
    "os.makedirs(cleaned_data_dir, exist_ok=True)\n",
    "\n",
    "# 5ï¸âƒ£ è·å–å½“å‰ç›®å½•ä¸‹æ‰€æœ‰ CSV æ–‡ä»¶\n",
    "csv_files = [f for f in os.listdir() if f.endswith(\".csv\")]\n",
    "\n",
    "# 6ï¸âƒ£ å®šä¹‰è–ªèµ„æ¸…ç†å‡½æ•°\n",
    "def clean_salary(salary):\n",
    "    if pd.isna(salary) or salary == \"\" or salary == \"Not Provided\":\n",
    "        return \"unknown\", \"unknown\", \"unknown\", \"unknown\"\n",
    "\n",
    "    # ç§»é™¤ $ å’Œ , åªä¿ç•™æ•°å­—ã€\".\" å’Œ \"-\"ï¼ˆé€‚ç”¨äºèŒƒå›´ï¼‰\n",
    "    salary = re.sub(r\"[\\$,]\", \"\", str(salary))\n",
    "\n",
    "    # æå–æ•°å€¼èŒƒå›´ï¼ˆå¦‚ \"80,000 - 110,000\" â†’ [80000, 110000]ï¼‰\n",
    "    salary_range = re.findall(r\"\\d+\\.\\d+|\\d+\", salary)\n",
    "\n",
    "    # è§£æè–ªèµ„èŒƒå›´\n",
    "    if len(salary_range) == 2:\n",
    "        low_salary = float(salary_range[0])\n",
    "        high_salary = float(salary_range[1])\n",
    "    elif len(salary_range) == 1:\n",
    "        low_salary = high_salary = float(salary_range[0])\n",
    "    else:\n",
    "        return \"unknown\", \"unknown\", \"unknown\", \"unknown\"\n",
    "\n",
    "    # è¯†åˆ«è–ªèµ„å•ä½å¹¶è½¬æ¢\n",
    "    if \"por aÃ±o\" in salary.lower():  # å¹´è–ª\n",
    "        return low_salary, high_salary, (low_salary + high_salary) / 2, \"year\"\n",
    "    elif \"por hora\" in salary.lower():  # æ—¶è–ªè½¬æ¢ä¸ºå¹´è–ªï¼ˆå‡è®¾ 2080 å·¥ä½œå°æ—¶/å¹´ï¼‰\n",
    "        return low_salary * 2080, high_salary * 2080, ((low_salary + high_salary) / 2) * 2080, \"hour\"\n",
    "    elif \"por mes\" in salary.lower():  # æœˆè–ªè½¬æ¢ä¸ºå¹´è–ª\n",
    "        return low_salary * 12, high_salary * 12, ((low_salary + high_salary) / 2) * 12, \"month\"\n",
    "    else:\n",
    "        return \"unknown\", \"unknown\", \"unknown\", \"unknown\"\n",
    "\n",
    "# 7ï¸âƒ£ å¤„ç†æ¯ä¸ª CSV æ–‡ä»¶\n",
    "for file in csv_files:\n",
    "    print(f\"ğŸ“‚ æ­£åœ¨å¤„ç†æ–‡ä»¶: {file}\")\n",
    "\n",
    "    # è¯»å–æ–‡ä»¶ç¼–ç \n",
    "    with open(file, \"rb\") as f:\n",
    "        raw_data = f.read(10000)  # è¯»å–å‰ 10000 å­—èŠ‚æ£€æµ‹ç¼–ç \n",
    "        detected_encoding = chardet.detect(raw_data)[\"encoding\"]\n",
    "\n",
    "    print(f\"ğŸ“Œ æ£€æµ‹åˆ°ç¼–ç : {detected_encoding}\")\n",
    "\n",
    "    # 8ï¸âƒ£ ä½¿ç”¨æ£€æµ‹åˆ°çš„ç¼–ç æ ¼å¼è¿›è¡Œè¯»å–\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding=detected_encoding)\n",
    "        print(f\"âœ… æˆåŠŸä½¿ç”¨ {detected_encoding} è¯»å– {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯»å– {file} å¤±è´¥ï¼Œä½¿ç”¨ {detected_encoding}ï¼Œå°è¯•å…¶ä»–ç¼–ç ...\")\n",
    "\n",
    "        # ä¾æ¬¡å°è¯• utf-8ã€ISO-8859-1ã€Windows-1252\n",
    "        encoding_attempts = [\"utf-8\", \"ISO-8859-1\", \"Windows-1252\"]\n",
    "        success = False\n",
    "\n",
    "        for enc in encoding_attempts:\n",
    "            try:\n",
    "                df = pd.read_csv(file, encoding=enc)\n",
    "                print(f\"âœ… æˆåŠŸä½¿ç”¨ {enc} è¯»å– {file}\")\n",
    "                success = True\n",
    "                break  # æˆåŠŸè¯»å–ï¼Œè·³å‡ºå¾ªç¯\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è¯»å– {file} å¤±è´¥ï¼Œå°è¯• {enc} ç¼–ç : {e}\")\n",
    "\n",
    "        if not success:\n",
    "            print(f\"â›” æ–‡ä»¶ {file} æ— æ³•è¯»å–ï¼Œè·³è¿‡å¤„ç†ã€‚\\n\")\n",
    "            continue  # è·³è¿‡æ— æ³•è¯»å–çš„æ–‡ä»¶\n",
    "\n",
    "    # 9ï¸âƒ£ è¯†åˆ«æ•°æ®é›†ä¸­çš„è–ªèµ„åˆ—ï¼ˆè‡ªåŠ¨åŒ¹é…åˆ—åå¤§å°å†™ï¼‰\n",
    "    def find_salary_columns(df):\n",
    "        salary_keywords = [\"salary\", \"low_salary\", \"high_salary\", \"mean_salary\"]\n",
    "        found_cols = {col.lower(): col for col in df.columns if any(keyword in col.lower() for keyword in salary_keywords)}\n",
    "        return found_cols\n",
    "\n",
    "    salary_col_map = find_salary_columns(df)\n",
    "\n",
    "    # ğŸ”Ÿ å¤„ç† `Salary` æ•°æ®\n",
    "    if \"salary\" in salary_col_map:\n",
    "        salary_col = salary_col_map[\"salary\"]\n",
    "        print(f\"ğŸ“Œ å‘ç°è–ªèµ„åˆ—: {salary_col}\")\n",
    "\n",
    "        # è®¡ç®—è–ªèµ„æ•°æ®å¹¶åˆ›å»ºæ–°åˆ—\n",
    "        df[[\"Low_Salary\", \"High_Salary\", \"Mean_Salary\", \"Salary_Frequency\"]] = df[salary_col].apply(lambda x: pd.Series(clean_salary(x)))\n",
    "\n",
    "    else:\n",
    "        print(f\"âš ï¸ æœªæ‰¾åˆ°è–ªèµ„åˆ—ï¼Œè·³è¿‡è–ªèµ„å¤„ç†ã€‚\")\n",
    "\n",
    "    # 1ï¸âƒ£1ï¸âƒ£ å¤„ç†ç¼ºå¤±å€¼ï¼ˆå¡«å…… \"unknown\"ï¼‰\n",
    "    missing_cols = [\"Low_Salary\", \"High_Salary\", \"Mean_Salary\", \"Salary_Frequency\"]\n",
    "    for col in missing_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"unknown\"\n",
    "\n",
    "    df.fillna(\"unknown\", inplace=True)\n",
    "\n",
    "    # 1ï¸âƒ£2ï¸âƒ£ ç¡®ä¿ `NaN` è½¬æ¢ä¸º `\"unknown\"`\n",
    "    for col in missing_cols:\n",
    "        df[col] = df[col].apply(lambda x: \"unknown\" if pd.isna(x) or x == \"\" else x)\n",
    "\n",
    "    # 1ï¸âƒ£3ï¸âƒ£ ç”Ÿæˆæ¸…ç†åæ–‡ä»¶å\n",
    "    cleaned_filename = f\"cleaned_{file}\"\n",
    "    cleaned_filepath = os.path.join(cleaned_data_dir, cleaned_filename)\n",
    "\n",
    "    # 1ï¸âƒ£4ï¸âƒ£ ä¿å­˜æ¸…ç†åçš„ CSV æ–‡ä»¶\n",
    "    df.to_csv(cleaned_filepath, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"âœ… æ¸…ç†å®Œæˆï¼Œå·²ä¿å­˜è‡³: {cleaned_filepath}\\n\")\n",
    "\n",
    "# 1ï¸âƒ£5ï¸âƒ£ å¤„ç†å®Œæˆæç¤º\n",
    "print(f\"ğŸ‰ æ‰€æœ‰ CSV æ–‡ä»¶å·²å¤„ç†å®Œæ¯•ï¼Œæ¸…ç†åçš„æ–‡ä»¶å­˜æ”¾åœ¨ `{cleaned_data_dir}` æ–‡ä»¶å¤¹ä¸­ï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9b8eb-8424-422f-a26c-2c7c0bb4124e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
