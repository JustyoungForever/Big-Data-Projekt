{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11a4ca30-f0cb-4f52-8d34-6abdabc7e10e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T01:18:14.997576Z",
     "iopub.status.busy": "2025-01-19T01:18:14.997246Z",
     "iopub.status.idle": "2025-01-19T01:18:15.336831Z",
     "shell.execute_reply": "2025-01-19T01:18:15.335983Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 读取 CSV 文件\n",
    "file_path = \"./ai_ml_jobs_linkedin.csv\"  # 替换为你的 CSV 文件路径\n",
    "\n",
    "df = pd.read_csv(file_path, encoding=\"utf-8\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f104876a-994f-4f00-b68c-b5f469b663ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T01:18:15.340138Z",
     "iopub.status.busy": "2025-01-19T01:18:15.339377Z",
     "iopub.status.idle": "2025-01-19T01:18:15.348702Z",
     "shell.execute_reply": "2025-01-19T01:18:15.347876Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1️⃣ 处理缺失值（改进 inplace=True）\n",
    "df = df.assign(\n",
    "    companyName=df[\"companyName\"].fillna(\"Unknown\"),\n",
    "    sector=df[\"sector\"].fillna(\"Unknown\"),\n",
    "    publishedAt=pd.to_datetime(df[\"publishedAt\"], errors=\"coerce\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a19c0e6-dfaf-429b-9338-9bc8b235d073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T01:18:15.351512Z",
     "iopub.status.busy": "2025-01-19T01:18:15.351087Z",
     "iopub.status.idle": "2025-01-19T01:18:15.357959Z",
     "shell.execute_reply": "2025-01-19T01:18:15.357191Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2️⃣ 清理 applicationsCount（提取数值）\n",
    "def clean_applications_count(value):\n",
    "    value = str(value)\n",
    "    value = re.sub(r'\\D', '', value)  # 只保留数字\n",
    "    return int(value) if value else None\n",
    "\n",
    "df[\"applicationsCount\"] = df[\"applicationsCount\"].apply(clean_applications_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8350a1d1-f0e5-495f-b7a0-d848a3cca4bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T01:18:15.360360Z",
     "iopub.status.busy": "2025-01-19T01:18:15.359982Z",
     "iopub.status.idle": "2025-01-19T01:18:15.366901Z",
     "shell.execute_reply": "2025-01-19T01:18:15.366135Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3️⃣ 标准化 contractType 和 experienceLevel\n",
    "df[\"contractType\"] = df[\"contractType\"].str.lower().str.strip()\n",
    "df[\"experienceLevel\"] = df[\"experienceLevel\"].str.lower().str.strip()\n",
    "df[\"workType\"] = df[\"workType\"].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e4d43b-9aa5-4aa8-8e6b-c2d6852e8d58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T01:18:15.369514Z",
     "iopub.status.busy": "2025-01-19T01:18:15.369095Z",
     "iopub.status.idle": "2025-01-19T01:18:15.470130Z",
     "shell.execute_reply": "2025-01-19T01:18:15.469341Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4️⃣ 清理 description（去除多余空格、换行符）\n",
    "df[\"description\"] = df[\"description\"].str.replace(r'\\s+', ' ', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b99da08-3bec-4571-ab93-2ec46c141ffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T01:18:15.472776Z",
     "iopub.status.busy": "2025-01-19T01:18:15.472508Z",
     "iopub.status.idle": "2025-01-19T01:18:20.751066Z",
     "shell.execute_reply": "2025-01-19T01:18:20.750264Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5 预定义 AI 技能关键词列表（从图片提取）\n",
    "ai_skills = [\n",
    "    \"3D Reconstruction\", \"Alexa\", \"Algorithm Analysis\", \"Algorithm Development\",\n",
    "    \"Artificial Intelligence (AI)\", \"Artificial Neural Networks\", \"Association Rules\",\n",
    "    \"Audio Synthesis\", \"Autoencoders\", \"Automated Clustering\", \"Automated Feature Engineering\",\n",
    "    \"Automated Reasoning\", \"Autoregressive Models\", \"Caffe\", \"Classification\", \"Cognitive Computing\",\n",
    "    \"Common Lisp\", \"Computational Geometry\", \"Computational Intelligence\", \"Computational Linguistics\",\n",
    "    \"Computer Vision\", \"Concept Drift Adaptation\", \"Conditional Image Generation\",\n",
    "    \"Convolutional Neural Networks (CNN)\", \"Data Structures\", \"Deep Learning\", \"dSPACE\",\n",
    "    \"Evolutionary Algorithms\", \"Expert Systems\", \"Facial Recognition\", \"Feature Extraction\",\n",
    "    \"Feature Selection\", \"Fuzzy Logic\", \"Gaussian 03\", \"Generative Adversarial Imitation Learning\",\n",
    "    \"Generative Design Optimization\", \"Generative Flow Models\", \"Generative Modeling\",\n",
    "    \"Generative Neural Networks\", \"Generative Optimization\", \"Generative Pre-Training\",\n",
    "    \"Generative Query Networks (GQNs)\", \"Generative Replay Memory\", \"Generative Synthesis\",\n",
    "    \"Gesture Recognition\", \"Graph Embeddings\", \"Graph Networks\", \"Graph Theory\",\n",
    "    \"Hyperparameter Optimization\", \"Hyperparameter Tuning\", \"IBM Watson\", \"Image Generation\",\n",
    "    \"Image Inpainting\", \"Image Processing\", \"Image Synthesis\", \"Information Extraction\",\n",
    "    \"Information Retrieval\", \"Intelligent Agents\", \"Jena\", \"Julia (Programming Language)\",\n",
    "    \"Keras\", \"Knowledge Discovery\", \"Knowledge Representation and Reasoning\", \"Linked Data\",\n",
    "    \"Lisp\", \"Machine Learning\", \"Meta-learning\", \"Microsoft Azure Machine Learning\",\n",
    "    \"Model Compression\", \"Model Interpretation\", \"Model Training\", \"Music Generation\",\n",
    "    \"Natural Language Generation\", \"Natural Language Processing (NLP)\",\n",
    "    \"Natural Language Understanding\", \"Neural Network Architecture Design\", \"Neural Networks\",\n",
    "    \"NLTK\", \"Object Recognition\", \"Ontologies\", \"OpenCV\", \"Pandas (Software)\",\n",
    "    \"Parallel Algorithms\", \"Parsing\", \"Pattern Recognition\", \"Perl Automation\",\n",
    "    \"Probabilistic Generative Models\", \"Probabilistic Programming\", \"Prompt Engineering\",\n",
    "    \"PyTorch\", \"Question Answering\", \"RapidMiner\", \"Recommender Systems\", \"Reinforcement Learning\",\n",
    "    \"Resource Description Framework (RDF)\", \"Scikit-Learn\", \"Semantic Technologies\",\n",
    "    \"Semantic Web\", \"Sentiment Analysis\", \"Smalltalk\", \"Speech Recognition\",\n",
    "    \"Statistical Inference\", \"Style Transfer\", \"Supervised Learning\", \"Support Vector Machine (SVM)\",\n",
    "    \"Synthetic Data Generation\", \"TensorFlow\", \"Text Analytics\", \"Text Classification\",\n",
    "    \"Text Generation\", \"Text Mining\", \"Text-to-Image Generation\", \"Theano\",\n",
    "    \"Time Series Forecasting\", \"Unsupervised Learning\", \"Variational Autoencoders\",\n",
    "    \"Variational Autoencoders (VAEs)\", \"Video Generation\", \"Web Mining\", \"Weka\", \"WordNet\"\n",
    "]\n",
    "\n",
    "#  提取 description 字段中的 AI 技能\n",
    "def extract_skills(description):\n",
    "    \"\"\"从职位描述中提取 AI 相关技能\"\"\"\n",
    "    found_skills = [skill for skill in ai_skills if re.search(rf'\\b{re.escape(skill)}\\b', description, re.IGNORECASE)]\n",
    "    return \", \".join(found_skills) if found_skills else None\n",
    "\n",
    "df[\"skills\"] = df[\"description\"].apply(extract_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d9bcb5c-c05d-438e-a4bc-d29ed2416377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T01:18:20.754169Z",
     "iopub.status.busy": "2025-01-19T01:18:20.753739Z",
     "iopub.status.idle": "2025-01-19T01:18:20.888371Z",
     "shell.execute_reply": "2025-01-19T01:18:20.887599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 数据清理完成，文件已保存至 /mnt/g/Nextcloud/FSU_Cloud/Big Data/Projekt/cleaned_data/cleaned_ai_ml_jobs.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 获取当前 Notebook (`clean_data.ipynb`) 所在目录\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 获取 `Projekt` 根目录（即 `raw_data` 的上一级目录）\n",
    "projekt_root = os.path.abspath(os.path.join(current_dir, \"..\", \"..\"))\n",
    "\n",
    "# 定义 `cleaned_data` 目录的正确路径\n",
    "cleaned_data_dir = os.path.join(projekt_root, \"cleaned_data\")\n",
    "\n",
    "# 确保 `cleaned_data` 目录存在\n",
    "os.makedirs(cleaned_data_dir, exist_ok=True)\n",
    "\n",
    "# 生成新的文件路径\n",
    "cleaned_file_path = os.path.join(cleaned_data_dir, \"cleaned_ai_ml_jobs.csv\")\n",
    "\n",
    "# 保存文件到 `Projekt/cleaned_data`\n",
    "df.to_csv(cleaned_file_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ 数据清理完成，文件已保存至 {cleaned_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
